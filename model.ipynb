{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "\n",
    "Take the work we did in the lessons further:\n",
    "\n",
    "What other types of models (i.e. different classifcation algorithms) could you use?\n",
    "How do the models compare when trained on term frequency data alone, instead of TF-IDF values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import acquire as a\n",
    "import prepare as prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text: str) -> list:\n",
    "    'A simple function to cleanup text data'\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    text = (text.encode('ascii', 'ignore')\n",
    "             .decode('utf-8', 'ignore')\n",
    "             .lower())\n",
    "    words = re.sub(r'[^\\w\\s]', '', text).split() # tokenization\n",
    "    return [wnl.lemmatize(word) for word in words if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"business\", \"sports\", \"technology\", \"entertainment\", \"science\", \"world\"]\n",
    "news_df = a.get_all_news_articles(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df=prep.prepare_data(news_df, 'content', ['said'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Need to have commemorative coins depicting Nee...</td>\n",
       "      <td>After javelin thrower Neeraj Chopra won a gold...</td>\n",
       "      <td>business</td>\n",
       "      <td>javelin thrower neeraj chopra gold medal tokyo...</td>\n",
       "      <td>javelin thrower neeraj chopra gold medal tokyo...</td>\n",
       "      <td>javelin thrower neeraj chopra gold medal tokyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Binance US CEO quits 3 months after joining ar...</td>\n",
       "      <td>Brian Brooks, CEO of the US arm of world's lar...</td>\n",
       "      <td>business</td>\n",
       "      <td>brian brooks ceo us arm worlds largest cryptoc...</td>\n",
       "      <td>brian brook ceo us arm world largest cryptocur...</td>\n",
       "      <td>brian brook ceo u arm world largest cryptocurr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Microsoft Co-founder Paul Allen's superyacht l...</td>\n",
       "      <td>A 414-foot superyacht, Octopus, once owned by ...</td>\n",
       "      <td>business</td>\n",
       "      <td>414foot superyacht octopus owned microsoft cof...</td>\n",
       "      <td>414foot superyacht octopu own microsoft cofoun...</td>\n",
       "      <td>414foot superyacht octopus owned microsoft cof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Melinda French Gates now owns $5.7 billion in ...</td>\n",
       "      <td>Melinda French Gates has received stocks that ...</td>\n",
       "      <td>business</td>\n",
       "      <td>melinda french gates received stocks worth 57 ...</td>\n",
       "      <td>melinda french gate receiv stock worth 57 bill...</td>\n",
       "      <td>melinda french gate received stock worth 57 bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Intend to pursue all avenues for Reliance deal...</td>\n",
       "      <td>Future Retail has said that it \"intends to pur...</td>\n",
       "      <td>business</td>\n",
       "      <td>future retail intends pursue available avenues...</td>\n",
       "      <td>futur retail intend pursu avail avenu conclud ...</td>\n",
       "      <td>future retail intends pursue available avenue ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Need to have commemorative coins depicting Nee...   \n",
       "1  Binance US CEO quits 3 months after joining ar...   \n",
       "2  Microsoft Co-founder Paul Allen's superyacht l...   \n",
       "3  Melinda French Gates now owns $5.7 billion in ...   \n",
       "4  Intend to pursue all avenues for Reliance deal...   \n",
       "\n",
       "                                             content  category  \\\n",
       "0  After javelin thrower Neeraj Chopra won a gold...  business   \n",
       "1  Brian Brooks, CEO of the US arm of world's lar...  business   \n",
       "2  A 414-foot superyacht, Octopus, once owned by ...  business   \n",
       "3  Melinda French Gates has received stocks that ...  business   \n",
       "4  Future Retail has said that it \"intends to pur...  business   \n",
       "\n",
       "                                               clean  \\\n",
       "0  javelin thrower neeraj chopra gold medal tokyo...   \n",
       "1  brian brooks ceo us arm worlds largest cryptoc...   \n",
       "2  414foot superyacht octopus owned microsoft cof...   \n",
       "3  melinda french gates received stocks worth 57 ...   \n",
       "4  future retail intends pursue available avenues...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  javelin thrower neeraj chopra gold medal tokyo...   \n",
       "1  brian brook ceo us arm world largest cryptocur...   \n",
       "2  414foot superyacht octopu own microsoft cofoun...   \n",
       "3  melinda french gate receiv stock worth 57 bill...   \n",
       "4  futur retail intend pursu avail avenu conclud ...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  javelin thrower neeraj chopra gold medal tokyo...  \n",
       "1  brian brook ceo u arm world largest cryptocurr...  \n",
       "2  414foot superyacht octopus owned microsoft cof...  \n",
       "3  melinda french gate received stock worth 57 bi...  \n",
       "4  future retail intends pursue available avenue ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<150x2593 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4713 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "bag_of_words = cv.fit_transform(news_df.lemmatized)\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to see what is inside of the sparse matrix\n",
    "bag_of_words.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>108</th>\n",
       "      <th>108th</th>\n",
       "      <th>109172</th>\n",
       "      <th>109run</th>\n",
       "      <th>11</th>\n",
       "      <th>110</th>\n",
       "      <th>11000</th>\n",
       "      <th>112</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>youngster</th>\n",
       "      <th>youre</th>\n",
       "      <th>youth</th>\n",
       "      <th>youve</th>\n",
       "      <th>zaranj</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zelda</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2593 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   10  100  108  108th  109172  109run  11  110  11000  112  ...  young  \\\n",
       "0   0    0    0      0       0       0   0    0      0    0  ...      0   \n",
       "1   0    0    0      0       0       0   0    0      0    0  ...      0   \n",
       "2   0    0    0      0       0       0   0    0      0    0  ...      0   \n",
       "3   0    0    0      0       0       0   0    0      0    0  ...      0   \n",
       "4   1    0    0      0       0       0   0    0      0    0  ...      0   \n",
       "\n",
       "   youngster  youre  youth  youve  zaranj  zealand  zelda  zone  zoom  \n",
       "0          0      0      0      0       0        0      0     0     0  \n",
       "1          0      0      0      0       0        0      0     0     0  \n",
       "2          0      0      0      0       0        0      0     0     0  \n",
       "3          0      0      0      0       0        0      0     0     0  \n",
       "4          0      0      0      0       0        0      0     0     0  \n",
       "\n",
       "[5 rows x 2593 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pprint(news_df.lemmatized)\n",
    "pd.DataFrame(bag_of_words.todense(), columns=cv.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>108</th>\n",
       "      <th>108th</th>\n",
       "      <th>109172</th>\n",
       "      <th>109run</th>\n",
       "      <th>11</th>\n",
       "      <th>110</th>\n",
       "      <th>11000</th>\n",
       "      <th>112</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>youngster</th>\n",
       "      <th>youre</th>\n",
       "      <th>youth</th>\n",
       "      <th>youve</th>\n",
       "      <th>zaranj</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zelda</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.123891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2593 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         10  100  108  108th  109172  109run   11  110  11000  112  ...  \\\n",
       "0  0.000000  0.0  0.0    0.0     0.0     0.0  0.0  0.0    0.0  0.0  ...   \n",
       "1  0.000000  0.0  0.0    0.0     0.0     0.0  0.0  0.0    0.0  0.0  ...   \n",
       "2  0.000000  0.0  0.0    0.0     0.0     0.0  0.0  0.0    0.0  0.0  ...   \n",
       "3  0.000000  0.0  0.0    0.0     0.0     0.0  0.0  0.0    0.0  0.0  ...   \n",
       "4  0.123891  0.0  0.0    0.0     0.0     0.0  0.0  0.0    0.0  0.0  ...   \n",
       "\n",
       "   young  youngster  youre  youth  youve  zaranj  zealand  zelda  zone  zoom  \n",
       "0    0.0        0.0    0.0    0.0    0.0     0.0      0.0    0.0   0.0   0.0  \n",
       "1    0.0        0.0    0.0    0.0    0.0     0.0      0.0    0.0   0.0   0.0  \n",
       "2    0.0        0.0    0.0    0.0    0.0     0.0      0.0    0.0   0.0   0.0  \n",
       "3    0.0        0.0    0.0    0.0    0.0     0.0      0.0    0.0   0.0   0.0  \n",
       "4    0.0        0.0    0.0    0.0    0.0     0.0      0.0    0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 2593 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidfs = tfidf.fit_transform(news_df.lemmatized)\n",
    "\n",
    "#pprint(news_df.lemmatized)\n",
    "pd.DataFrame(tfidfs.todense(), columns=tfidf.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(2, 2))\n",
    "bag_of_words = cv.fit_transform(news_df.lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10 amazon</th>\n",
       "      <th>10 esa</th>\n",
       "      <th>10 kg</th>\n",
       "      <th>100 billion</th>\n",
       "      <th>100 suggests</th>\n",
       "      <th>100 suspect</th>\n",
       "      <th>108 ongoing</th>\n",
       "      <th>108th minute</th>\n",
       "      <th>109run inning</th>\n",
       "      <th>11 woman</th>\n",
       "      <th>...</th>\n",
       "      <th>zaranj sheberghan</th>\n",
       "      <th>zealand government</th>\n",
       "      <th>zealand new</th>\n",
       "      <th>zealand threeyear</th>\n",
       "      <th>zealand visa</th>\n",
       "      <th>zelda game</th>\n",
       "      <th>zone 45</th>\n",
       "      <th>zone across</th>\n",
       "      <th>zone reserve</th>\n",
       "      <th>zoom tv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4658 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   10 amazon  10 esa  10 kg  100 billion  100 suggests  100 suspect  \\\n",
       "0          0       0      0            0             0            0   \n",
       "1          0       0      0            0             0            0   \n",
       "2          0       0      0            0             0            0   \n",
       "3          0       0      0            0             0            0   \n",
       "4          1       0      0            0             0            0   \n",
       "\n",
       "   108 ongoing  108th minute  109run inning  11 woman  ...  zaranj sheberghan  \\\n",
       "0            0             0              0         0  ...                  0   \n",
       "1            0             0              0         0  ...                  0   \n",
       "2            0             0              0         0  ...                  0   \n",
       "3            0             0              0         0  ...                  0   \n",
       "4            0             0              0         0  ...                  0   \n",
       "\n",
       "   zealand government  zealand new  zealand threeyear  zealand visa  \\\n",
       "0                   0            0                  0             0   \n",
       "1                   0            0                  0             0   \n",
       "2                   0            0                  0             0   \n",
       "3                   0            0                  0             0   \n",
       "4                   0            0                  0             0   \n",
       "\n",
       "   zelda game  zone 45  zone across  zone reserve  zoom tv  \n",
       "0           0        0            0             0        0  \n",
       "1           0        0            0             0        0  \n",
       "2           0        0            0             0        0  \n",
       "3           0        0            0             0        0  \n",
       "4           0        0            0             0        0  \n",
       "\n",
       "[5 rows x 4658 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(bag_of_words.todense(), columns=cv.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(news_df.content.apply(clean).apply(' '.join))\n",
    "y = news_df.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5416666666666666"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=5)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "tree.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5416666666666666"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy is the % of times our model predicted correctly\n",
    "(tree.predict(X_train) == y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26666666666666666"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
